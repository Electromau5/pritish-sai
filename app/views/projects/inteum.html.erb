<div class="container" style="margin-top: 25px">
		<div class="p-name" style="text-align:center">
		<h3 class="project-name-label">PROJECT: </h3>
		<h3 class="project-name">USABILITY EVALUATION OF THE INVENTOR PORTAL</h3><br><br>
	</div>
	<hr/>
	<div class="links">
		<div class="link-image link-image-2"><%= link_to image_tag('misc/website.png'), 'https://www.inteum.com/', target: '_blank' %></div> 
	</div><br />
	<h3 class="project-deliverables" style="text-align: center; font-size: 30px; font-family: 'Raleway-Light', sans-serif">DELIVERABLES</h3><br />
	<p class="highlights">"Usability Evaluation of a Tech Transfer Portal"</p>
			<div class="dev-project-roles">
			<div class="dev-role">HEURISTIC EVALUATION</div>
			<div class="dev-role">RECRUITING USERS</div>
			<div class="dev-role">TEST PLANNING</div>
			<div class="dev-role">EVALUATION WITH USERS</div>
			<div class="dev-role">PRESENTING RESULTS TO CLIENT</div>
		</div><br>
		<div class="jumbotron">
	
			<h3 class="process-title">PROJECT SUMMARY</h3>
			<p class="process-description">
				This project required a Usability Evaluation of the Inteum Inventor Portal. The Inventor Portal is a product of the company, ‘Inteum’ which is primarily in the field of Tech Transfer, a process that involves all administrative, and legal paperwork involved with turning an invention into a marketable product. 
			</p>
			<h4 class="highlights">"The Usability Evaluation required observing and evaluating every UI element on the portal."</h4>
			<p class="process-description">
				Before we started working on the evaluation process, we met with two representatives from Inteum who briefed us on the business's history, current plans as well as their vision for the future of the Inventor Portal. This meeting gave us the opportunity to understand the fundamentals of Tech Transfer (an area that none of us were familiar with), have a first look into the Inventor Portal and get briefed on the company's objectives.
			</p>
			<p class="process-description">
				 The Usability Evaluation required observing and evaluating every UI element on the portal. The process required a heuristic evaluation followed by a series of usability tests that consisted of 1 pilot and 9 official sessions. The tests were recorded and the results were brought back to the client for a final presentation
			</p>
		</div>
		<div class="jumbotron">
			<h3 class="process-title">OBJECTIVES</h3>
				<ol class="process-description">
					<li>Identify obstacles that users may face while creating and/or editing a disclosure. These obstacles are only centered on the interface and the overall usability of the portal.</li>
					<li>Identify if a user would recommend the portal to a potential inventor who needs a patent to make their product marketable.</li>
					<li>What recommendation would they give to their own Tech Transfer Office (TTO) based on their experience with the Inventor Portal.</li>
				</ol>
		</div>
		<div class="jumbotron">
			<h3 class="process-title">METHODOLOGY</h3>
			<h4 class="process-subtitle">Aspects of the Inventor Portal We Evaluated</h4>
			<p class="process-description">
				The goal of the evaluation was to learn about the experience of inventors in using the system’s core disclosure creation functions. To do this, we created 2 test scenarios. Scenario A had the participants work through the entire disclosure creation process. They began on the dashboard of the Inventor Portal, created a new invention, gave it a title, moved through each section of the form that makes up the disclosure editing portion of the web app, and finally submit the disclosure to the TTO. This scenario allowed us to evaluate the ease of use and intuitiveness of the entire disclosure creation process. 
			</p>
			<h4 class="highlights">"The goal of the evaluation was to learn about the experience of inventors in using the system’s core disclosure creation functions"</h4>
			<p class="process-description">
				As part of the larger disclosure process may also involve using the Inventor Portal to communicate back and forth with the TTO to get more information or make clarifications, we also included a short scenario for editing disclosures. Scenario B evaluated the discoverability of remarks left by Inventor Portal administrator users (who would typically be employees of a TTO). Participants were then asked to make the requested changes to the Inventor Portal and resubmit it. 
			</p>
			<h4 class="process-subtitle">Dates of Study</h4>
			<p class="process-description">
				Our evaluation took place over a two week period ranging from April 6th - April 20th. Our pilot study took place on April 6th and the following evaluation took place April 11-20th. The specific dates that the evaluation took place were: April 11th, 12th, 16th, and 20th. Each evaluation took around one hour total.
			</p>
			<h4 class="process-subtitle">Evaluation Environment</h4>
			<p class="process-description">
				All evaluations took place at RIT in Golisano room 2293 and 2289. The evaluation took place in the evaluation room where one moderator sat with the participant. The observation room was behind a 2-way mirror, and there was always one to three observers in the observation room.
			</p>
			<div class="secondary-images-hifi">
					<%= image_tag('inteum/room.png') %>
			</div><br>
			<h4 class="process-subtitle">Participants</h4>
			<p class="process-description">
				In total we conducted this evaluation with nine participants: 6 graduate students, one TTO staff member, one professor, and one undergraduate student. Each participant had varying levels of familiarity with the concept of Tech Transfer.
				<div class="secondary-images-hifi">
					<%= image_tag('inteum/table1.png') %>
				</div><br>
			</p>
			<h4 class="process-subtitle">Tasks and Scenarios</h4>
			<p class="process-description">
				We evaluated the Inventor Portal through two scenarios: creating a new disclosure and editing an existing disclosure based on a remark left by a member of their university’s TTO. The task and subtasks for each scenario are as follows:
			</p>
				<p class="process-description"><b>Scenario A-Create a Disclosure</b></p>
			<p class="process-description">	
				Scenario A involved the participant creating a disclosure on the Inventor Portal. All information needed to fill out the disclosure was provided in an information sheet. The Task List below details each step/subtask. 
			</p>
			<p class="process-description"><b>Task List 1:</b> Create a disclosure for your project</p> 
				<ol class="process-description">
					<li>Subtask 1: Select the right type of disclosure.</li>
					<li>Subtask 2: Upload the correct document.</li>
					<li>Subtask 3: Add a subscriber.</li>
					<li>Subtask 4: Add an inventor.</li>
					<li>Subtask 5: Add an interest.</li>
					<li>Subtask 6: Add a marketing target.</li>
					<li>Subtask 7: Add funding.</li>
					<li>Subtask 8: Submit the disclosure for review.</li> 
				</ol>

<p class="process-description"><b>Scenario B-Edit a Disclosure  (10 minutes)</b></p>
<p class="process-description">	
Scenario B involved the participant editing an existing disclosure based on a remark made by the administrator of the portal. The remark clearly detailed what needs to be edited in the disclosure.
</p>
<p class="process-description">	
	<b>Task List:</b> Edit an existing disclosure for a project
</p>
<ol class="process-description">
<li>Subtask 1: Find the disclosure that was returned to the inventor.</li>
<li>Subtask 2: Find comments made by the admin.</li>
<li>Subtask 3: Edit the disclosure according to the comments.</li>
<li>Subtask 4: Submit the new version of the disclosure.</li>
</ol>
			</p>
			<h4 class="process-subtitle">Test Design Matrix</h4>
			<p class="process-description">
				For our evaluation we used a within-subjects design which means that each participant attempted both scenarios. The order of the scenarios were counterbalanced to minimize any learning effects that could potentially influence their performance in their second scenario.
				<div class="secondary-images-hifi">
						<%= image_tag('inteum/table2.png') %>
				</div><br>

			</p>
			<h4 class="process-subtitle">Measurements Taken</h4>
			<p class="process-description">
				For each evaluation, several measurements were taken including a standardized questionnaire to assess usability known as the System Usability Scale (SUS), task success and failure rates, and the participant’s opinions about their interactions with Inventor Portal. 
			</p>
			<p class="process-description">
				According to usability.gov, “The System Usability Scale (SUS) provides a “quick and dirty”, reliable tool for measuring the usability.   It consists of a 10 item questionnaire with five response options for respondents; from Strongly agree to Strongly disagree.  Originally created by John Brooke in 1986, it allows you to evaluate a wide variety of products and services, including hardware, software, mobile devices, websites and applications.”  (https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html)
			</p>
			<p class="process-description">
				Task success was defined as successfully completing a subtask using data provided in the Information Sheet. What the participant entered for each section did not have to match what was in the Information Sheet exactly, as long as they demonstrated an understanding of how to input information into each section of the portal.
			</p>
			<h4 class="highlights">"Task success was defined as successfully completing a subtask using data provided in the Information Sheet"</h4>
			<p class="process-description">
				At the end of the post-evaluation questionnaire we asked participants if they would recommend this system to their university’s TTO and why or why not. We asked these questions to assess the participant’s opinions regarding the portal and it’s ease of use. Performance during the evaluation does not always reflect the impression they are left with after using the system.
			</p>
			<h4 class="process-subtitle">Deviations from Test Plan</h4>
			<ul class="process-description">
				<li>The information sheet was changed to specify what type of disclosure was required to be input by the participant. Some participants selected disclosure types that were created in the test environment, but weren’t intended to be used in this evaluation.</li>
				<li>The name of the account holder from which the participant would complete the task was added to the moderator script. This made certain elements of the tasks clearer, as the current user’s name appears a few times during the process, and participants needed to know that was supposed to be them.</li>
				<li>The participant was given some time to review the information sheet before the task officially started.
				<li>The moderator script also included when to open the internet tab integral to each task and scenario.</li>
				<li>A pre-task checklist was created to make sure everything was in place.</li>
				<li>The definition of Tech Transfer was added to the moderator’s script so it could easily be communicated to the participant in the event they wanted information on it before the task.</li>
				<li>The moderator also included a prompt to specify what a disclosure was to a participant
				<li>We decided to not count the number of errors participants made for each task/subtask. Instead we focused on identifying the most significant obstacles participants faced.</li>
			</ul>
			<div class="jumbotron">
				<h3 class="process-title">FINDINGS</h3>
				<h4 class="process-subtitle">Quantitative Results</h4>
				<p class="process-description">
					The task success and failure rate is recorded and calculated for each subtask in Scenario A and Scenario B.
				</p>
				<p class="process-description">
					<b>Scenario A:</b> Create a disclosure
				</p>
				<div class="secondary-images-hifi">
					<%= image_tag('inteum/table3.png') %>
				</div><br>
				<p class="process-description">
					<b>Scenario B:</b> Edit a disclosure
				</p>
				<div class="secondary-images-hifi">
					<%= image_tag('inteum/table4.png') %>
				</div>
				<h4 class="process-subtitle">SUS(System Usability Scale)</h4>
				<p class="process-description">
					We used a standardized questionnaire System Usability Scale questionnaire as a post-evaluation questionnaire. The score of the Inventor Portal is 65.3, which means participants tend to think that the Inventor Portal is not very easy to use. A SUS score above a 68 would be considered above average and anything below 68 is below average in terms of user satisfaction.
					<div class="secondary-images-hifi">
						<%= image_tag('inteum/graph1.png') %>
					</div><br>
					<div class="secondary-images-hifi">
						<%= image_tag('inteum/graph2.png') %>
					</div><br>
					<div class="secondary-images-hifi">
						<%= image_tag('inteum/graph3.png') %>
					</div>
				</p>
				<h4 class="process-subtitle">Participant Feedback</h4>
				<p class="process-description">
					We also asked the participants about their opinions of the Inventor Portal in the post-evaluation questionnaire. The positive feedback indicates that:
					<ul class="process-description">
						<li>the search function is convenient</li>
						<li>the layout of the website is consistent and straightforward</li>
					</ul>
				</p>
				<p class="process-description">
					The negative feedback is listed below: 
					<ul class="process-description">
					<li>There are a lot of fields to fill in and the process is tedious, such as adding inventors individually.</li>
					<li>It is tricky to enter contributions and significance while not knowing all the limitations. 
</li>
					<li>The use of different terms “Remark” and “Comment” for the same meaning is confusing.
</li>
					<li>Comments made by TTO is not distinguished from those made by team members, which made it difficult to find.
</li>
					</ul>
				</p>
				<h4 class="process-subtitle">Usability Problems Identified</h4>
				<p class="process-description">
					Creating a new disclosure
				</p>
				<ol class="process-description">
					<li>Participants were confused to what ‘significance’ meant and made several assumptions about it (Heuristic 2, Internal Consistency). In addition, participants also had issues dividing the level of contribution among all the inventors (contributor) for an invention (Heuristic 5, Frequently Used Functions Optimize).</li>
					<li>Participants assumed that multiple fields (e.g. contributors, marketing targets) could be added and saved at the same time (Heuristic 5, Frequently Used Functions Optimize; Heuristic 12, User Control and Freedom).</li>
					<li>The error notification “Total contribution cannot be greater than 100” appeared even when the contribution input was below 100 (Heuristic 7, Perceptibility of Feedback).</li>
					<li>Some of the terms on the form seemed to cause confusion. Users came up with varying definitions for terms like Significance, Interests, and Marketing Targets (Speak the User’s Language). </li>
				</ol>
				<p class="process-description">
					Editing a disclosure
				</p>
				<ol class="process-description">
					<li>Some participants did not find the remark made by the admin easily. Many expected a message from the TTO to be highlighted or otherwise made to stand out from other elements of the disclosure.</li>
					<li>One participant was confused over whether the comment made on an existing disclosure was the same as the remark that an inventor could make creating a new disclosure.</li>
				</ol>
			</div>

</div>